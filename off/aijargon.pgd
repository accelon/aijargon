 {id:"aijargon",title:"AI行話",aligncaption:"中",author:"善那"}
_	這是AI行話巢注式示範，什麼是^[語言大模型]
algorithm	為解決某個特定問題，事先編寫好的^[代碼]，有指定的輸入（參量）以及計算結果。
alibaba	阿里巴巴集團。
api	應用程序接口，允許外部程序調用^[模型]功能的標準化方式。
arm	省電的^[精簡指令集架構]，廣泛用於移動設備。
attention	^[神經網路]中聚焦關鍵信息的機制，常用於^[語言大模型]。
backpropagation	通過計算損失函數梯度，反向調整^[參數]的^[訓練]方法。
basis	長度為1，與坐標軸對齊的單位向量，用於定義空間坐標。
batch	^[訓練]時一次性處理的數據子集，用於加速計算。
batch	一次處理的^[數據集]子集，加速^[訓練]。
bit	計算機最小存儲單位，可表示0或1兩種狀態。
byte	8個^[位元]，可表達2＾8=256種狀態。
chatgpt	由 OpenAI 開發的 AI ^[大語言模型]，能理解並生成自然語言，廣泛用於聊天、問答與任務協助。
cisc	指令功能強大但數量多，優化困難，相對^[精簡指令集]。
clang	誕生於1972年，高效的結構化^[強類型]^[編程語言]，以底層控制能力和手動內存管理著稱，廣泛用於操作系統、嵌入式系統和性能要求高的應用。
cloudcomputing	通過遠程服務器提供計算資源，常用於^[訓練]和部署^[模型]。
cnn	應用^[卷積]的^[神經網路]，擅長圖像識別。
code	計算機可以執行的命令，包括數值計算、數據存取、信號傳遞等等。
compile	將源代碼轉譯為機器執行指令。
component	構成^[張量]的單獨數值或元素。
constant	程序^[運行]過程中，不會改變的^[數據]。相對於^[變量]。
convolution	用於提取特徵的數學運算，常見於圖像處理^[神經網路]。
cpplang	誕生於1983年，高效、廣泛使用的^[強類型]^[編程語言]，在^[c語言]的基礎上添加^[面向對象]、^[泛型]等語法而成。
cpu	計算機的核心計算與控制單元，依^[指令集架構]分類。
cuda	^[英偉達]開發的^[圖形處理器]並行計算平台。
data	^[數字化]之後，計算機可以處理的信息。可粗分為^[常量]及^[變量]。
dataset	用於^[訓練]或測試^[模型]的數據集合，通常分為訓練集、驗證集和測試集。
datatype	處理器可處理的基本數據形態，通常可分為若干位元組的整數，浮點數、字符串等等。
deepseek	^[幻方量化]推出的^[開源]^[大語言模型]，大幅降低^[訓練]成本。
diffusionmodel	通過反向擴散過程^[訓練]^[神經網路]，用於圖像生成或去噪。
digitize	將信息轉換為數字（0與1）表達方式。
dropout	^[訓練]中隨機丟棄^[神經元]，防止^[過擬合]的技術。
embedding	將文本或圖像轉為^[向量]，捕捉語義關係的技術。
epoch	完整遍歷一次^[數據集]的^[訓練]過程。
fileformat	數據在文件中的組織方式，類似詞典的「體例」。
finetune	以完成的大^[模型]為基礎，只調整其中少量的^[參數]，比從頭^[訓練]划算。
frontenddev	指構建網站或應用程序的用戶界面部分，主要使用HTML、CSS 和 ^[javascript]。
gen	由生成器與判別器組成，通過對抗^[訓練]生成逼真數據。
generic	允許^[強類型]^[編程語言]在^[實例]化階段時，才決定^[數據類型]的設計方法。
gguf	Georgi Gerganov發布的^[模型]^[文件格式]，兼容性好，布署便利，並支持^[微調]。
gpu	專為圖形和矩陣計算設計的處理器，比^[中央處理器]更高效。
gradientdescent	通過迭代調整^[參數]，最小化^[損失函數]的算法。
inference	利用訓練好的^[模型]進行預測或生成。
instance	將^[程序]安排的變量，配置^[內存]。
interpret	逐步執行^[源代碼]，犧牲運行效率。
isa	處理器能夠接受的基本命令，通常包括：數據讀寫、算術邏輯、流程控制三大部份。
javascript	誕生於1995年，輕量級、直譯型語言，^[前端開發]最重要的^[編程語言]。
learning	^[訓練]的同義語。
llm	以大量自然語言文本材料，^[訓練]而成的^[參數]量巨大的^[模型]。
lossfunction	衡量^[模型]預測與實際結果差距的函數，用於指導^[訓練]。
matrix	由若干行和列構個的矩形陣列。線性代數之基礎概念，廣泛用以解決工程問題。
model	^[訓練]完成^[神經網路]，通常以大型文件存在。
neuralnetwork	模擬人腦^[神經元]連結的網路。以應對基於規則的編程所難以解決的問題，如視覺及語音識別。
neuron	^[神經網路]的基本單元，若干個輸入，與各自的權重相積的總合，經非綫性傳遞函數，得到一個^[標量]輸出。
nvidia	一家位於聖克拉拉的^[圖形處理器]的芯片設計公司。
opensource	公開軟件的^[源代碼]。
overfitting	^[模型]過於適應^[訓練]數據，^[泛化]能力差。
generization	是指AI模型在訓練後，能將學到的知識應用到未見過的新數據上，展現適應能力。
parameter	^[神經元]的每個輸入的權重值。神經網路的規模取決於它的總量。
plang	用以編寫出程序的語言。
program	為完成特定任務（菜品）的一系列步驟，由^[代碼]（^[變量]宣告）及必要數據構。
prompt	用以引導^[語言大模型]生成特定輸出的輸入文本，通常需要精心設計。
python	誕生於1991年，以簡潔、易讀的語法著稱的高階^[編程語言]。廣泛應用於數據分析、機器學習和科學計算。
pytorch	^[python] 的^[開源]機器學習框架。
quantization	以損失^[浮點數精度]為代價的^[模型]壓縮技術。^[位元]數越小，壓縮效果越好而精度越低。
qwen	^[阿里]推出的^[大語言模型]。
rankoftensor	m維空間中，每個^[分量]所需的[基向量]個數。m維空間的n秩^[張量]有 m＾n 個^[分量]。
regressionanalysis	分析自變量和因變量之間的關係，並以函數表達。
regularization	通過限制^[參數]複雜度，防止^[過擬合]的技術。
risc	指令簡單，利於並行優化的^[指令集架構]，相對^[複雜指令集]。
rnn	處理序列數據的^[神經網路]，具記憶功能。
runtime	運行程序的階段。
safetensors	即安全（指不會被修改的）^[張量]，由huggingface推出的^[模型]^[文件格式]。
scalar	0秩^[張量]，可理解為一個數值。
sourcecode	人類編寫的文件，經^[編譯]或^[直譯]為計算機可以運行的^[程序]。
stronglytyped	在^[編譯]階段須決定^[數據類型]。相對於^[弱類型]。
supervisedlearning	以輸入與預期輸出（^[回歸分析]或者^[分類]）為素材的^[訓練]方式。
tensor	^[神經網路]基本數據結構，用以儲存^[參數]。可用多維陣列表達。
tensorflow	由Google推出的^[開源]機器學習框架，適用於^[訓練]和部署^[模型]。
throughput	單位時間內輸入或輸出^[符元]的數量。
token	字符串的最基礎處理單元。
tokenizer	將字符串分解成^[符元]的^[程序]。
training	喂入數據，經由算法不斷調整^[參數]，即所謂的機器學習。
transformer	基於^[注意力]機制的^[神經網路]架構，廣泛應用於自然語言處理。
unsupervisedlearning	以足夠多的自然語言文本為素材，讓機器^[學習]其中之規律。
variable	程序^[運行]中會改變的^[數據]。相對於^[常量]。
vector	1秩^[張量]，每個^[分量]僅由一個^[基向量]定義。
weaklytyped	在^[運行]階段才須決定^[數據類型]。相對於^[強類型]。
x86	^[英代爾]開發的^[複雜指令集]^[中央處理器]架構。